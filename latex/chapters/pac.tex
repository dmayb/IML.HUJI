\chapter{PAC Theory of Statistical Learning}
    \section{Theoretical Framework For Learning}
        \subsection{Data-Generation Model}
        \subsection{The Realizability Assumption}
        \subsection{Learning As A Game - First Attempt}
        \subsection{Probably- and Approximately Correct Learners}
    \section{No Free Lunch and Hypothesis Classes}
        \subsection{No Free Lunch!}
        \subsection{Restricting for Hypothesis Classes}
        \subsection{Learning As A Game - Final Attempt}
        \subsection{Example: Threshold Functions}
    
    \section{PAC Learnability of Finite Hypothesis Classes}
    
    \section{VC-Dimension}
        \subsection{Formal Definition}
        \subsection{VC-Dimension of Finite Hypothesis Classes}
        \subsection{Example: Axis Aligned Rectangles}
        \subsection{Example: Half-Spaces}
        
    \section{Agnostic PAC: Extending Framework}
        \subsection{Data-Generation Model Over $\mathcal{X}\times\mathcal{Y}$}
        \subsection{Relaxing Realizability Assumption}
        \subsection{Introducing General Loss Functions}
        \subsection{Agnostic PAC Learnability}
    
    \section{Uniform Convergence Property}
        \subsection{$\varepsilon$-Representative Datasets}
        \subsection{Achieving Uniformity In $\mathcal{H}$ and $\mathcal{D}$}
            \subsubsection{The Case Of Finite $\mathcal{H}$}
            \subsubsection{The General Case - Infinite $\mathcal{H}$}
    
    \section{The Fundamental Theorem of Statistical Learning}